{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import torch as tch\n",
    "# use proper seaborn styling\n",
    "import seaborn as sns\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test-x.txt and test-y.txt are comma-seperated files of float/int values, corresponding to the board state and the policy respectively\n",
    "x = np.loadtxt(\"datasets/dataset1-x.txt\", delimiter=\",\")\n",
    "y = np.loadtxt(\"datasets/dataset1-y.txt\", delimiter=\",\")\n",
    "\n",
    "print(f\"{len(x)} datapoints loaded!\")\n",
    "assert len(x) == len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enforce that each y value sums to 1\n",
    "y = y / np.sum(y, axis=1)[:, None]\n",
    "\n",
    "# split the dataset into training and validation sets\n",
    "split = int(len(x) * 0.9)\n",
    "x_train = x[:split]\n",
    "y_train = y[:split]\n",
    "x_val = x[split:]\n",
    "y_val = y[split:]\n",
    "\n",
    "# shuffle the datasets\n",
    "perm_train = np.random.permutation(len(x_train))\n",
    "x_train = x_train[perm_train]\n",
    "y_train = y_train[perm_train]\n",
    "perm_val = np.random.permutation(len(x_val))\n",
    "x_val = x_val[perm_val]\n",
    "y_val = y_val[perm_val]\n",
    "\n",
    "# convert to tensors\n",
    "x_train = tch.tensor(x_train, dtype=tch.float)\n",
    "y_train = tch.tensor(y_train, dtype=tch.float)\n",
    "print(f\"x_train has dims {x_train.shape}\")\n",
    "print(f\"y_train has dims {y_train.shape}\")\n",
    "x_val = tch.tensor(x_val, dtype=tch.float)\n",
    "y_val = tch.tensor(y_val, dtype=tch.float)\n",
    "print(f\"x_val has dims {x_val.shape}\")\n",
    "print(f\"y_val has dims {y_val.shape}\")\n",
    "\n",
    "# create a dataset class\n",
    "class GomokuDataset(tch.utils.data.Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "# create dataloaders\n",
    "train_dataset = GomokuDataset(x_train, y_train)\n",
    "val_dataset = GomokuDataset(x_val, y_val)\n",
    "train_loader = tch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = tch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_shaped = x_train.reshape(-1, 2, 9, 9)\n",
    "y_shaped = y_train.reshape(-1, 9, 9)\n",
    "\n",
    "# show some sample data\n",
    "fig, axs = plt.subplots(5, 4, figsize=(12, 10))\n",
    "for i in range(5):\n",
    "    # left plot is the board state\n",
    "    board = x_shaped[i, 0] + x_shaped[i, 1] / 2\n",
    "    axs[i, 0].imshow(board, cmap=\"gray\")\n",
    "    # right plot is the policy\n",
    "    policy = y_shaped[i]\n",
    "    axs[i, 1].imshow(policy, cmap=\"inferno\")\n",
    "\n",
    "    # plot the nonzero board values\n",
    "    nonzero_board = board != 0\n",
    "    axs[i, 2].imshow(nonzero_board, vmin=0, vmax=1)\n",
    "\n",
    "    # plot the zero policy values\n",
    "    zero_policy = policy == 0\n",
    "    axs[i, 3].imshow(zero_policy, vmin=0, vmax=1)\n",
    "\n",
    "# remove the gridlines\n",
    "for ax in axs.flatten():\n",
    "    ax.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an extremely simple model\n",
    "from matplotlib.pylab import f\n",
    "\n",
    "\n",
    "class PolicyModel(tch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = tch.nn.Linear(9*9*2, 9*9)\n",
    "        self.softmax = tch.nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "# define a convolutional model\n",
    "# this is ever so slightly more complicated than the previous model\n",
    "# as we need to reshape the input to be 4-dimensional\n",
    "class ConvPolicyModel(tch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.relu    = tch.nn.ReLU()\n",
    "        self.conv1   = tch.nn.Conv2d(2, 8, 3, padding=1) # 2x9x9 -> 8x9x9\n",
    "        self.conv2   = tch.nn.Conv2d(8, 2, 3)            # 8x9x9 -> 2x7x7\n",
    "        self.fc      = tch.nn.Linear(2 * 7 * 7, 9 * 9)\n",
    "        self.softmax = tch.nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 2, 9, 9)\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        # flatten\n",
    "        x = x.view(-1, 2 * 7 * 7)\n",
    "        x = self.fc(x)\n",
    "        # x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model and optimizer\n",
    "model = ConvPolicyModel()\n",
    "optimizer = tch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "\n",
    "# create a loss function to match the probability distribution\n",
    "def loss_fn(prediction_logits, target_distribution):\n",
    "    return tch.nn.functional.binary_cross_entropy(tch.nn.functional.softmax(prediction_logits, dim=1), target_distribution)\n",
    "\n",
    "# create a function for masking off illegal moves\n",
    "def mask_illegal_moves(model_prediction, board):\n",
    "    # return model_prediction\n",
    "    # model_prediction is an 81-element vector of probabilities\n",
    "    # board is a 81 * 2 = 162-element vector of occupancies\n",
    "    # we need to set all illegal moves to 0,\n",
    "    # and then renormalize the probabilities\n",
    "    # so that they sum to 1 again\n",
    "    # first, get a mask of all illegal moves\n",
    "    illegal_moves = board[:, :81] + board[:, 81:]\n",
    "    # now set all illegal moves to 0\n",
    "    model_prediction = tch.where(illegal_moves != 0, tch.zeros_like(model_prediction), model_prediction)\n",
    "\n",
    "    return model_prediction\n",
    "\n",
    "# create a training loop\n",
    "def train(model, optimizer, loss_fn, train_loader, val_loader, epochs=20, device=\"cpu\"):\n",
    "    losses = []\n",
    "    val_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}\")\n",
    "        model.train()\n",
    "        for batch_idx, (board_state, search_policy) in enumerate(train_loader):\n",
    "            board_state = board_state.to(device)\n",
    "            search_policy = search_policy.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            raw_policy = model(board_state)\n",
    "            masked_policy = mask_illegal_moves(raw_policy, board_state)\n",
    "            loss = loss_fn(masked_policy, search_policy)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_value = loss.item()\n",
    "            total_batch_idx = epoch * len(train_loader) + batch_idx\n",
    "            losses.append((total_batch_idx, loss_value))\n",
    "            if batch_idx % 64 == 0:\n",
    "                print(f\"Training batch {batch_idx}/{len(train_loader)}: loss {loss_value}\")\n",
    "        val_loss = 0.0\n",
    "        model.eval()\n",
    "        with tch.no_grad():\n",
    "            for batch_idx, (board_state, search_policy) in enumerate(val_loader):\n",
    "                board_state = board_state.to(device)\n",
    "                search_policy = search_policy.to(device)\n",
    "                raw_policy = model(board_state)\n",
    "                masked_policy = mask_illegal_moves(raw_policy, board_state)\n",
    "                val_loss += loss_fn(masked_policy, search_policy).item()\n",
    "            val_loss /= len(val_loader)\n",
    "            total_batch_idx = (epoch + 1) * len(train_loader)\n",
    "            val_losses.append((total_batch_idx, val_loss))\n",
    "            print(f\"Validation loss {val_loss}\")\n",
    "    return losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "# print(f\"Training on device {tch.cuda.get_device_name(0)}\")\n",
    "loss_trace, val_loss_trace = train(model, optimizer, loss_fn, train_loader, val_loader, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss trace and validation loss trace\n",
    "loss_trace = np.array(loss_trace)\n",
    "val_loss_trace = np.array(val_loss_trace)\n",
    "plt.plot(loss_trace[:, 0], loss_trace[:, 1])\n",
    "plt.plot(val_loss_trace[:, 0], val_loss_trace[:, 1])\n",
    "plt.xlabel(\"Batch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend([\"Training loss\", \"Validation loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "tch.save(model.state_dict(), \"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the model's predictions\n",
    "model.eval()\n",
    "\n",
    "# get five random items from the validation set\n",
    "rand_idx = np.random.randint(len(val_dataset), size=10)\n",
    "x_sample = x_val[rand_idx]\n",
    "y_sample = y_val[rand_idx]\n",
    "y_pred_raw = model(x_sample)\n",
    "y_pred = mask_illegal_moves(y_pred_raw, x_sample)\n",
    "# apply softmax to get a probability distribution\n",
    "y_pred = tch.nn.functional.softmax(y_pred, dim=1)\n",
    "\n",
    "x_sample = x_sample.reshape(-1, 2, 9, 9)\n",
    "y_sample = y_sample.reshape(-1, 9, 9)\n",
    "y_pred = y_pred.detach().numpy().reshape(-1, 9, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results\n",
    "# the first column is the board state\n",
    "# the second column is the search policy\n",
    "# the third column is the neural network policy\n",
    "fig, axs = plt.subplots(5, 3, figsize=(7, 13))\n",
    "# label the columns\n",
    "axs[0, 0].set_title(\"Board state\")\n",
    "axs[0, 1].set_title(\"Search policy\")\n",
    "axs[0, 2].set_title(\"Neural network policy\")\n",
    "for i in range(5):\n",
    "    board_one = x_sample[i][0]\n",
    "    board_two = x_sample[i][1]\n",
    "    search = y_sample[i]\n",
    "    nn = y_pred[i]\n",
    "    pieces_on_first_board = board_one.flatten().sum()\n",
    "    pieces_on_second_board = board_two.flatten().sum()\n",
    "    x_to_move = pieces_on_first_board != pieces_on_second_board\n",
    "    if not x_to_move:\n",
    "        board_one, board_two = board_two, board_one\n",
    "    board = np.stack([board_one, np.zeros((9, 9)), board_two], axis=2) / 1.5\n",
    "    search_policy_board = np.stack([search, search, search], axis=2)\n",
    "    nn_policy_board = np.stack([nn, nn, nn], axis=2)\n",
    "\n",
    "    # renormalise the policies so that the max prediction is 1.0\n",
    "    search_policy_board *= 1.0 / search_policy_board.max()\n",
    "    nn_policy_board *= 1.0 / nn_policy_board.max()\n",
    "\n",
    "    search_policy_board += board\n",
    "    nn_policy_board += board\n",
    "    axs[i, 0].imshow(board, vmin=0, vmax=255, cmap=\"inferno\")\n",
    "    axs[i, 1].imshow(search_policy_board, vmin=0, vmax=255)\n",
    "    axs[i, 2].imshow(nn_policy_board, vmin=0, vmax=255)\n",
    "\n",
    "# set gridlines to 1x1\n",
    "for ax in axs.flatten():\n",
    "    ax.set_xticks(np.arange(-.5, 9, 1))\n",
    "    ax.set_yticks(np.arange(-.5, 9, 1))\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.grid(True, color=\"grey\", linewidth=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export model to ONNX\n",
    "onnx_model_path = \"model.onnx\"\n",
    "\n",
    "# create a dummy input\n",
    "dummy_input = tch.randn(1, 162)\n",
    "\n",
    "# export the model\n",
    "tch.onnx.export(model, dummy_input, onnx_model_path, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify the model with onnxruntime\n",
    "common_input_data = x_sample\n",
    "pytorch_net_output = model(common_input_data).detach().numpy()\n",
    "import onnxruntime as ort\n",
    "ort_session = ort.InferenceSession(onnx_model_path)\n",
    "onnx_net_output = []\n",
    "for i in range(len(common_input_data)):\n",
    "    input_thing = {'onnx::Reshape_0': common_input_data[i].numpy().reshape(1, 162)}\n",
    "    onnx_net_output.append(ort_session.run(None, input_thing)[0])\n",
    "onnx_net_output = np.squeeze(np.array(onnx_net_output), axis=1)\n",
    "\n",
    "# compare the outputs\n",
    "assert pytorch_net_output.shape == onnx_net_output.shape\n",
    "assert np.allclose(pytorch_net_output, onnx_net_output, rtol=1e-03, atol=1e-05)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
